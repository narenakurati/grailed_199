---
title: "grailed_199_rmd"
author: "Naren Akurati"
date: "1/15/2019"
output: html_document
---

```{r, echo = FALSE}
library(testthat)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gridExtra))
library(class)
library(ISLR)
suppressPackageStartupMessages(library(caret))
library(e1071)
suppressPackageStartupMessages(library(MASS))
library(reshape2)
library(ggcorrplot)
suppressPackageStartupMessages(library(boot))
suppressPackageStartupMessages(library(resample))
library(rpart)
library(tree)
suppressPackageStartupMessages(library(randomForest))
library(rvest)
library(stringr)
```

#Using rvest to pull first load page of data
```{r, warning=FALSE, tidy.opts=list(width.cutoff=80), tidy = TRUE}
grailed <- read_html("https://www.grailed.com/sold/")
grailed

sample_url <- read_html('https://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature')

#test <- grailed %>% html_nodes("homepage-wrapper") %>% html_nodes("feed-item")
#test <- grailed %>% html_nodes('img')
#test <- grailed %>% html_nodes('.feed-item:nth-child(2)')
test <- grailed %>% html_nodes('.feed-item:nth-child(1) img') %>% html_attr("href")
test <- grailed %>% html_nodes('feed-item') %>% html_attr("href")
test <- grailed %>% html_attr("img")

#.feed-item~ .feed-item+ .feed-item img , .feed-item:nth-child(1) img

test <- read_html("https://www.grailed.com/sold/")
html_nodes(test, "feed-item")
html_attr(test, "class")
```

#After navigating to item page
```{r, warning=FALSE, tidy.opts=list(width.cutoff=80), tidy = TRUE}
#specific item

sold_item_test <- read_html('https://www.grailed.com/listings/7804580-Acne-Studios-Acne-Studios-Kai-Reverse-Pav16-Pre-Beige-Melange-wool-sweater')

title <- sold_item_test %>% html_nodes('title') %>% html_text()
price <- sold_item_test %>% html_nodes('._sold') %>% html_text()
brand <- sold_item_test %>% html_nodes('.jumbo a') %>% html_text()
size <- sold_item_test %>% html_nodes('.listing-size') %>% html_text()
#NW user <- sold_item_test %>% html_nodes('.ListingSellerCard') %>% html_text()

script <- sold_item_test %>% html_nodes('script') %>% html_text()
#we can pull time from this with "sold_at"
#we can also pull user from "username"

time <- script[7]
time <- as.character(time)
time <- regmatches(time, gregexpr("(?<=sold_at).*(?=sold_price.)", time, perl = TRUE))
time <- gsub("[\"]","", time); time <- gsub(",","", time); time <- str_sub(time, 2)

user <- script[7]
user <- as.character(user)
user <- regmatches(user, gregexpr("(?<=username).*(?=avatar_url)", user, perl = TRUE))
user <- gsub("[\"]","", user); user <- gsub(",","", user); user <- str_sub(user, 2)

data <- setNames(data.frame(matrix(ncol = 6, nrow = 1000)), c("title", "price", "brand", "size", "size", "time"))
#data$title[1] <- title
#data
#write.csv(time, file = "beans.txt")
```

#A function that will take URL as input as pull all relavent data
```{r, warning=FALSE, tidy.opts=list(width.cutoff=80), tidy = TRUE}
data <- setNames(data.frame(matrix(ncol = 6, nrow = 10)), c("title", "price", "brand", "size", "size", "time"))

pull_and_store <- function(url){
  
  temp <- matrix(ncol = 6, nrow = 1)
    
  sold_item_test <- read_html(url)
  
  title <- sold_item_test %>% html_nodes('title') %>% html_text()
  price <- sold_item_test %>% html_nodes('._sold') %>% html_text()
  brand <- sold_item_test %>% html_nodes('.jumbo a') %>% html_text()
  size <- sold_item_test %>% html_nodes('.listing-size') %>% html_text()
  
  script <- sold_item_test %>% html_nodes('script') %>% html_text()
  
  time <- script[7]
  time <- as.character(time)
  time <- regmatches(time, gregexpr("(?<=sold_at).*(?=sold_price.)", time, perl = TRUE))
  time <- gsub("[\"]","", time); time <- gsub(",","", time); time <- str_sub(time, 2)
  
  user <- script[7]
  user <- as.character(user)
  user <- regmatches(user, gregexpr("(?<=username).*(?=avatar_url)", user, perl = TRUE))
  user <- gsub("[\"]","", user); user <- gsub(",","", user); user <- str_sub(user, 2)
  
  temp[1,1] <- title
  temp[1,2] <- price
  temp[1,3] <- brand
  temp[1,4] <- size
  temp[1,5] <- time
  temp[1,6] <- user
  
  return(temp)
}

url <- 'https://www.grailed.com/listings/7804580-Acne-Studios-Acne-Studios-Kai-Reverse-Pav16-Pre-Beige-Melange-wool-sweater'
pull_and_store(url)
data[1,] <- pull_and_store(url)
```

#Automate data retrieval
```{r, warning=FALSE, tidy.opts=list(width.cutoff=80), tidy = TRUE}
sold_url <- 'https://www.grailed.com/sold'
sold_page <- read_html(sold_url)
image_url <- sold_page %>% html_nodes('') %*% html_attr('href')
image_url <- sold_page %>% html_nodes(xpath = '//*[@id="homepage-v2"]/div/div/div[2]/div/div[2]/div/div[2]/div[1]') %>% html_attr('href')

```
